import requests
from bs4 import BeautifulSoup
import datetime
import json
import re
import os

URL = "https://app.mspa.shop/"
README_FILE = "README.md"

def fetch_sponsor_data():
    """çˆ¬å–æ’è¡Œæ¦œä¿¡æ¯ï¼ˆæ ¹æ®å®é™…HTMLç»“æ„è‡ªè¡Œè°ƒæ•´é€‰æ‹©å™¨ï¼‰"""
    headers = {
        "User-Agent": "Mozilla/5.0 (Windows NT 10.0; Win64; x64) "
                      "AppleWebKit/537.36 (KHTML, like Gecko) "
                      "Chrome/120.0.0.0 Safari/537.36"
    }
    try:
        r = requests.get(URL, headers=headers, timeout=15)
        r.raise_for_status()
    except Exception as e:
        print(f"âš ï¸ è¯·æ±‚å¤±è´¥: {e}")
        return []

    soup = BeautifulSoup(r.text, "html.parser")

    sponsors = []
    for item in soup.select(".sponsor-item"):
        username = item.select_one(".username")
        amount = item.select_one(".amount")

        if username and amount:
            num = ''.join(c for c in amount.text if c.isdigit())
            if num and int(num) > 60:
                sponsors.append({
                    "username": username.text.strip(),
                    "amount": int(num)
                })
    return sponsors


def format_sponsor_section(sponsors):
    """æ ¼å¼åŒ–è¾“å‡ºæ–‡æœ¬"""
    timestamp = datetime.datetime.utcnow().strftime("%Y-%m-%d %H:%M UTC")
    sponsor_md = "\n".join(
        [f"- **{s['username']}** â€” ğŸ’° {s['amount']}" for s in sponsors]
    ) or "_æš‚æ— æ•°æ®_"

    return f"""
---

### ğŸ† èµåŠ©æ’è¡Œæ¦œï¼ˆè‡ªåŠ¨æ›´æ–°ï¼‰

> æ•°æ®æ¥æºï¼š[MSPA Shop]({URL})  
> æ›´æ–°æ—¶é—´ï¼š{timestamp}

{sponsor_md}

ï¼ˆæœ¬æ®µå†…å®¹ç”± GitHub Actions è‡ªåŠ¨æ›´æ–°ï¼‰
"""


def update_readme(sponsors):
    """æ›´æ–° README.mdï¼Œä»ç¬¬ 88 è¡Œå¼€å§‹æ›¿æ¢"""
    if not os.path.exists(README_FILE):
        print("âŒ æœªæ‰¾åˆ° README.md æ–‡ä»¶ï¼")
        return

    with open(README_FILE, "r", encoding="utf-8") as f:
        lines = f.readlines()

    # ç¡®ä¿è‡³å°‘æœ‰87è¡Œ
    while len(lines) < 87:
        lines.append("\n")

    # ä¿ç•™å‰87è¡Œï¼Œæ›´æ–°ä¹‹åçš„å†…å®¹
    prefix = "".join(lines[:87])
    new_section = format_sponsor_section(sponsors)

    with open(README_FILE, "w", encoding="utf-8") as f:
        f.write(prefix + new_section)

    print("âœ… README.md å·²æ›´æ–°ã€‚")


if __name__ == "__main__":
    data = fetch_sponsor_data()
    update_readme(data)
    print(json.dumps(data, ensure_ascii=False, indent=2))
