# update_readme.py
import requests
from bs4 import BeautifulSoup
import datetime
import json
import os
import re

# ç›®æ ‡ URLï¼ˆä½ æä¾›çš„ ipï¼‰
URL = "http://31.97.51.107:8500/"
README_FILE = "README.md"
MIN_AMOUNT = 60  # åªæå–å¤§äºæ­¤æ•°çš„èµåŠ©


def fetch_sponsor_data():
    """
    æŠ“å– sponsor åˆ—è¡¨å¹¶è¿”å› [{'username':..., 'amount':...}, ...]
    éœ€è¦æ ¹æ®é¡µé¢å®é™… DOM è°ƒæ•´é€‰æ‹©å™¨ï¼ˆä¸‹é¢å°è¯•äº†å‡ ç§å¸¸è§æ–¹æ¡ˆï¼‰
    """
    headers = {
        "User-Agent": "Mozilla/5.0 (Windows NT 10.0; Win64; x64) "
                      "AppleWebKit/537.36 (KHTML, like Gecko) "
                      "Chrome/120.0.0.0 Safari/537.36"
    }
    try:
        r = requests.get(URL, headers=headers, timeout=20)
        r.raise_for_status()
    except Exception as e:
        print(f"âš ï¸ è¯·æ±‚å¤±è´¥: {e}")
        return []

    soup = BeautifulSoup(r.text, "html.parser")

    results = []

    # --- å°è¯•å¤šç§å¸¸è§ç»“æ„æ¥æå–ç”¨æˆ·åå’Œé‡‘é¢ ---
    # ä¼˜å…ˆçº§ï¼šæ˜¾å¼ class -> è¡¨æ ¼ -> åˆ—è¡¨æ–‡æœ¬
    # 1) æ˜ç¡®çš„ sponsor-item / username / amount
    for item in soup.select(".sponsor-item"):
        name_el = item.select_one(".username") or item.select_one(".name") or item.select_one("h3")
        amt_el = item.select_one(".amount") or item.select_one(".money") or item.select_one(".price")
        if name_el and amt_el:
            name = name_el.get_text(strip=True)
            amt = extract_number(amt_el.get_text())
            if amt is not None and amt > MIN_AMOUNT:
                results.append({"username": name, "amount": amt})

    # 2) è¡¨æ ¼å½¢å¼ï¼š<table><tr><td>name</td><td>amount</td></tr>
    if not results:
        table_rows = soup.select("table tr")
        for tr in table_rows:
            cols = [td.get_text(strip=True) for td in tr.find_all(["td", "th"])]
            if len(cols) >= 2:
                # å‡è®¾æœ€åä¸€åˆ—æ˜¯é‡‘é¢ï¼Œç¬¬ä¸€åˆ—æˆ–ç¬¬äºŒåˆ—æ˜¯åç§°
                name = cols[0]
                amt = extract_number(cols[-1])
                if amt is not None and amt > MIN_AMOUNT:
                    results.append({"username": name, "amount": amt})

    # 3) åˆ—è¡¨æˆ–çº¯æ–‡æœ¬æŸ¥æ‰¾ï¼šç±»ä¼¼ "ç”¨æˆ·å â€” ï¿¥120"
    if not results:
        text = soup.get_text(separator="\n")
        for line in text.splitlines():
            # æ‰¾åˆ°æœ‰æ•°å­—çš„é’±é‡‘é¢è¡Œ
            if re.search(r"\d", line):
                amt = extract_number(line)
                if amt is not None and amt > MIN_AMOUNT:
                    # å°è¯•æŠŠç”¨æˆ·åè®¾ä¸ºæ•°å­—å‰çš„æ–‡æœ¬ï¼ˆæœ€å¤š 40 charsï¼‰
                    name = line.strip()
                    # å»æ‰é‡‘é¢æ–‡æœ¬ï¼Œè®©åå­—æ›´å¹²å‡€
                    name = re.sub(r"[\d\.,\sï¿¥$Â¥USDusd,]+$", "", name).strip()
                    if not name:
                        name = "unknown"
                    results.append({"username": name[:60], "amount": amt})

    # å»é‡å¹¶æŒ‰é‡‘é¢é™åºæ’åºï¼ˆè‹¥ç”¨æˆ·åé‡å¤ï¼Œä¿ç•™æœ€é«˜çš„ä¸€æ¡ï¼‰
    dedup = {}
    for r in results:
        key = r["username"]
        if key not in dedup or r["amount"] > dedup[key]:
            dedup[key] = r["amount"]

    final = [{"username": k, "amount": v} for k, v in dedup.items()]
    final.sort(key=lambda x: x["amount"], reverse=True)
    return final


def extract_number(s: str):
    """
    ä»å­—ç¬¦ä¸²ä¸­æå–ç¬¬ä¸€ä¸ªæ•°å­—ï¼ˆæ•´æ•°æˆ–å°æ•°ï¼‰ï¼Œè¿”å› float æˆ– None
    ä¾‹å­: "ï¿¥120" -> 120.0, "120.5 USD" -> 120.5
    """
    if not s:
        return None
    s = s.replace(",", "")  # å»åƒåˆ†ä½é€—å·
    m = re.search(r"(-?\d+(?:\.\d+)?)", s)
    if not m:
        return None
    try:
        val = float(m.group(1))
        return val
    except:
        return None


def format_sponsor_section(sponsors):
    """ç”Ÿæˆ markdown æ®µè½"""
    timestamp = datetime.datetime.utcnow().strftime("%Y-%m-%d %H:%M UTC")
    if not sponsors:
        sponsor_md = "_æš‚æ— æ•°æ®_"
    else:
        sponsor_md = "\n".join([f"- **{s['username']}** â€” ğŸ’° {format_amount(s['amount'])}" for s in sponsors])

    return f"""
---

### ğŸ† èµåŠ©æ’è¡Œæ¦œï¼ˆè‡ªåŠ¨æ›´æ–°ï¼‰

> æ•°æ®æ¥æºï¼š[{URL}]({URL})  
> æ›´æ–°æ—¶é—´ï¼š{timestamp}

{sponsor_md}

ï¼ˆæœ¬æ®µå†…å®¹ç”± GitHub Actions è‡ªåŠ¨æ›´æ–°ï¼‰
"""


def format_amount(x):
    # å»æ‰å°æ•°ä½ .0ï¼Œä¿ç•™æ•´æ•°æˆ–ä¸€ä½å°æ•°
    if abs(x - int(x)) < 1e-9:
        return str(int(x))
    else:
        return f"{x:.2f}"


def update_readme(sponsors):
    """ä¿ç•™å‰ 87 è¡Œï¼Œä»ç¬¬ 88 è¡Œå†™å…¥æ–°æ®µè½ï¼›è‹¥æ— æ•°æ®åˆ™ä¸ä¿®æ”¹æ–‡ä»¶"""
    if not os.path.exists(README_FILE):
        print("âŒ æœªæ‰¾åˆ° README.md æ–‡ä»¶ï¼")
        return

    with open(README_FILE, "r", encoding="utf-8") as f:
        lines = f.readlines()

    # ç¡®ä¿è‡³å°‘æœ‰ 87 è¡Œ
    while len(lines) < 87:
        lines.append("\n")

    if not sponsors:
        print("âš ï¸ æœªè·å–åˆ°æ–°æ•°æ®ï¼Œä¿ç•™åŸæ’è¡Œæ¦œå†…å®¹ã€‚")
        return

    prefix = "".join(lines[:87])
    new_section = format_sponsor_section(sponsors)

    with open(README_FILE, "w", encoding="utf-8") as f:
        f.write(prefix + new_section)

    print("âœ… README.md å·²æ›´æ–°ã€‚")


if __name__ == "__main__":
    data = fetch_sponsor_data()
    # æ‰“å° JSON ç»“æœåˆ°æ—¥å¿—ï¼Œæ–¹ä¾¿è°ƒè¯•
    print(json.dumps(data, ensure_ascii=False, indent=2))
    update_readme(data)
